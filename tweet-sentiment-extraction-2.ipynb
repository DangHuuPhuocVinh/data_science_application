{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Preface**\n**This project was inspired and referenced in [TensorFlow roBERTa - [0.705]](https://www.kaggle.com/code/cdeotte/tensorflow-roberta-0-705)**","metadata":{}},{"cell_type":"markdown","source":"# **1/ About team**\n|StuID  |        Name       |     Kaggle    |       Github      |\n|-------|-------------------|---------------|-------------------|\n|1752052|Dang Huu Phuoc Vinh|[V_Notebook](https://www.kaggle.com/danghuuphuocvinh)|[V_Github](https://github.com/DangHuuPhuocVinh/data_science_application)\n|1753097|Le Nguyen Minh Tam |[T_Notebook](https://www.kaggle.com/minhtamlenguyen)|[T_Github](https://github.com/lnmtam1999)","metadata":{}},{"cell_type":"markdown","source":"# **2/ About competition**","metadata":{}},{"cell_type":"markdown","source":"## **2.1/ Name of competition**\n**[Tweet Sentiment Extraction](https://www.kaggle.com/competitions/tweet-sentiment-extraction) organized by [Kaggle](https://www.kaggle.com/)**","metadata":{}},{"cell_type":"markdown","source":"## **2.2/ Prize**\n**15000 USD**","metadata":{}},{"cell_type":"markdown","source":"# **2.3/ Description**\n  **E.g: \"My ridiculous dog is amazing.\" [sentiment: positive]**\n\n  **With all of the tweets circulating every second it is hard to tell whether the sentiment behind a specific tweet will impact a company, or a person's, brand for being viral (positive), or devastate profit because it strikes a negative tone. Capturing sentiment in language is important in these times where decisions and reactions are created and updated in seconds. But, which words actually lead to the sentiment description? In this competition you will need to pick out the part of the tweet (word or phrase) that reflects the sentiment.**\n\n  **In this competition we've extracted support phrases from [Figure Eight's Data for Everyone platform](https://appen.com/datasets-resource-center/). The dataset is titled Sentiment Analysis: Emotion in Text tweets with existing sentiment labels, used here under creative commons attribution 4.0. international licence. Your objective in this competition is to construct a model that can do the same - look at the labeled sentiment for a given tweet and figure out what word or phrase best supports it.**","metadata":{}},{"cell_type":"markdown","source":"# **2.4/ Input and Output**\n- **Input: textID, text and sentiment**\n- **Output: selected_text**","metadata":{}},{"cell_type":"markdown","source":"# **2.5/ Columns**\n-  **textID - unique ID for each piece of text**\n-  **text - the text of the tweet**\n-  **sentiment - the general sentiment of the tweet**\n-  **selected_text - [train only] the text that supports the tweet's sentiment**","metadata":{}},{"cell_type":"markdown","source":"# **2.6/ Meaningful**\n- **After doing this project, we can have a dataset with the phrases that were selected for using at any other NLP project**\n- **Can use for detecting some keywords that have sentiment** ","metadata":{}},{"cell_type":"markdown","source":"# **2.7/ Evaluation**\n ![img](https://user-images.githubusercontent.com/35680794/174698744-57b2f116-fbe4-4fb6-9216-2e83e0494dca.png)","metadata":{}},{"cell_type":"markdown","source":"# **3/ Model roBERTa for this project**","metadata":{}},{"cell_type":"markdown","source":"# **4/ Developing the project**","metadata":{}},{"cell_type":"markdown","source":"# Import Libraries, Data and Tokenizer","metadata":{}},{"cell_type":"code","source":"import pandas as pd, numpy as np\nimport tensorflow as tf\nimport tensorflow.keras.backend as K\nfrom sklearn.model_selection import StratifiedKFold\nfrom transformers import *\nimport tokenizers\nprint('TF version',tf.__version__)","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2022-07-10T19:03:37.249400Z","iopub.execute_input":"2022-07-10T19:03:37.249683Z","iopub.status.idle":"2022-07-10T19:03:37.256307Z","shell.execute_reply.started":"2022-07-10T19:03:37.249641Z","shell.execute_reply":"2022-07-10T19:03:37.255411Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"First of all, we use tokenizer to convert the word to array for the computer can understand.","metadata":{}},{"cell_type":"code","source":"MAX_LEN = 96\nPATH = '../input/tf-roberta/'\ntokenizer = tokenizers.ByteLevelBPETokenizer(\n    vocab_file=PATH+'vocab-roberta-base.json', \n    merges_file=PATH+'merges-roberta-base.txt', \n    lowercase=True,\n    add_prefix_space=True\n)\nsentiment_id = {'positive': 1313, 'negative': 2430, 'neutral': 7974}\ntrain = pd.read_csv('../input/tweet-sentiment-extraction/train.csv').fillna('')\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2022-07-10T19:03:40.525552Z","iopub.execute_input":"2022-07-10T19:03:40.525850Z","iopub.status.idle":"2022-07-10T19:03:40.902687Z","shell.execute_reply.started":"2022-07-10T19:03:40.525819Z","shell.execute_reply":"2022-07-10T19:03:40.901896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**MAX_LEN** = 96 then for each training row, RoBERTa receives 96 tokens. The reason to use **lowercase** and **add_prefix_space** because when spelling with RoBERTa :\" helllo\", \"hello\", \" Hello\", and \"Hello\" use the same \" hello\" token.","metadata":{}},{"cell_type":"markdown","source":"# Training data\n","metadata":{}},{"cell_type":"code","source":"ct = train.shape[0]\ninput_ids = np.ones((ct,MAX_LEN),dtype='int32')\nattention_mask = np.zeros((ct,MAX_LEN),dtype='int32')\ntoken_type_ids = np.zeros((ct,MAX_LEN),dtype='int32')\nstart_tokens = np.zeros((ct,MAX_LEN),dtype='int32')\nend_tokens = np.zeros((ct,MAX_LEN),dtype='int32')\n\nfor k in range(train.shape[0]):\n    \n    # FIND OVERLAP\n    text1 = \" \"+\" \".join(train.loc[k,'text'].split())\n    text2 = \" \".join(train.loc[k,'selected_text'].split())\n    idx = text1.find(text2)\n    chars = np.zeros((len(text1)))\n    chars[idx:idx+len(text2)]=1\n    if text1[idx-1]==' ': chars[idx-1] = 1 \n    enc = tokenizer.encode(text1) \n        \n    # ID_OFFSETS\n    offsets = []; idx=0\n    for t in enc.ids:\n        w = tokenizer.decode([t])\n        offsets.append((idx,idx+len(w)))\n        idx += len(w)\n    \n    # START END TOKENS\n    toks = []\n    for i,(a,b) in enumerate(offsets):\n        sm = np.sum(chars[a:b])\n        if sm>0: toks.append(i) \n        \n    s_tok = sentiment_id[train.loc[k,'sentiment']]\n    input_ids[k,:len(enc.ids)+5] = [0] + enc.ids + [2,2] + [s_tok] + [2]\n    attention_mask[k,:len(enc.ids)+5] = 1\n    if len(toks)>0:\n        start_tokens[k,toks[0]+1] = 1\n        end_tokens[k,toks[-1]+1] = 1","metadata":{"execution":{"iopub.status.busy":"2022-07-10T19:03:44.265840Z","iopub.execute_input":"2022-07-10T19:03:44.266109Z","iopub.status.idle":"2022-07-10T19:03:53.105947Z","shell.execute_reply.started":"2022-07-10T19:03:44.266080Z","shell.execute_reply":"2022-07-10T19:03:53.105081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Test Data","metadata":{}},{"cell_type":"code","source":"test = pd.read_csv('../input/tweet-sentiment-extraction/test.csv').fillna('')\n\nct = test.shape[0]\ninput_ids_t = np.ones((ct,MAX_LEN),dtype='int32')\nattention_mask_t = np.zeros((ct,MAX_LEN),dtype='int32')\ntoken_type_ids_t = np.zeros((ct,MAX_LEN),dtype='int32')\n\nfor k in range(test.shape[0]):\n        \n    # INPUT_IDS\n    text1 = \" \"+\" \".join(test.loc[k,'text'].split())\n    enc = tokenizer.encode(text1)                \n    s_tok = sentiment_id[test.loc[k,'sentiment']]\n    input_ids_t[k,:len(enc.ids)+5] = [0] + enc.ids + [2,2] + [s_tok] + [2]\n    attention_mask_t[k,:len(enc.ids)+5] = 1","metadata":{"execution":{"iopub.status.busy":"2022-07-10T19:04:17.943856Z","iopub.execute_input":"2022-07-10T19:04:17.944124Z","iopub.status.idle":"2022-07-10T19:04:18.241347Z","shell.execute_reply.started":"2022-07-10T19:04:17.944095Z","shell.execute_reply":"2022-07-10T19:04:18.240640Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"if the original text is [ i][ am][ having][ a][ great][ day]</s>[ positive]</s> with tokens 0,1,2,3,4,5,6,7,8,9,10 and the selected text is \"great day\", then the training has start index = 5 and end index = 6.\n\nIf our model also predicts a = 5 and b = 6 and we try to select the text from [ i][ am][ having][ a][ great][ day], the indices 5 and 6 will not return \"great day\". Instead we must use tokens[4:6] to get great day. We subtract 1 because the is now removed. And we add 1 to b because python indexing for list[3:5] does not return 5 it only returns 3, 4","metadata":{}},{"cell_type":"markdown","source":"# Build roBERTa model\n","metadata":{}},{"cell_type":"code","source":"def build_model():\n    ids = tf.keras.layers.Input((MAX_LEN,), dtype=tf.int32)\n    att = tf.keras.layers.Input((MAX_LEN,), dtype=tf.int32)\n    tok = tf.keras.layers.Input((MAX_LEN,), dtype=tf.int32)\n\n    config = RobertaConfig.from_pretrained(PATH+'config-roberta-base.json')\n    bert_model = TFRobertaModel.from_pretrained(PATH+'pretrained-roberta-base.h5',config=config)\n    x = bert_model(ids,attention_mask=att,token_type_ids=tok)\n    \n    x1 = tf.keras.layers.Dropout(0.1)(x[0]) \n    x1 = tf.keras.layers.Conv1D(1,1)(x1)\n    x1 = tf.keras.layers.Flatten()(x1)\n    x1 = tf.keras.layers.Activation('softmax')(x1)\n    \n    x2 = tf.keras.layers.Dropout(0.1)(x[0]) \n    x2 = tf.keras.layers.Conv1D(1,1)(x2)\n    x2 = tf.keras.layers.Flatten()(x2)\n    x2 = tf.keras.layers.Activation('softmax')(x2)\n\n    model = tf.keras.models.Model(inputs=[ids, att, tok], outputs=[x1,x2])\n    optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5)\n    model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-07-10T19:05:21.352259Z","iopub.execute_input":"2022-07-10T19:05:21.352602Z","iopub.status.idle":"2022-07-10T19:05:21.364895Z","shell.execute_reply.started":"2022-07-10T19:05:21.352569Z","shell.execute_reply":"2022-07-10T19:05:21.364038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create metric\n","metadata":{}},{"cell_type":"code","source":"def jaccard(str1, str2): \n    a = set(str1.lower().split()) \n    b = set(str2.lower().split())\n    if (len(a)==0) & (len(b)==0): return 0.5\n    c = a.intersection(b)\n    return float(len(c)) / (len(a) + len(b) - len(c))","metadata":{"execution":{"iopub.status.busy":"2022-07-10T19:06:16.388632Z","iopub.execute_input":"2022-07-10T19:06:16.388950Z","iopub.status.idle":"2022-07-10T19:06:16.395186Z","shell.execute_reply.started":"2022-07-10T19:06:16.388923Z","shell.execute_reply":"2022-07-10T19:06:16.394374Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train roBERTa model","metadata":{}},{"cell_type":"code","source":"jac = []; VER='v0'; DISPLAY=1 # USE display=1 FOR INTERACTIVE\noof_start = np.zeros((input_ids.shape[0],MAX_LEN))\noof_end = np.zeros((input_ids.shape[0],MAX_LEN))\npreds_start = np.zeros((input_ids_t.shape[0],MAX_LEN))\npreds_end = np.zeros((input_ids_t.shape[0],MAX_LEN))\n\nskf = StratifiedKFold(n_splits=5,shuffle=True,random_state=777)\nfor fold,(idxT,idxV) in enumerate(skf.split(input_ids,train.sentiment.values)):\n\n    print('#'*25)\n    print('### FOLD %i'%(fold+1))\n    print('#'*25)\n    \n    K.clear_session()\n    model = build_model()\n        \n    sv = tf.keras.callbacks.ModelCheckpoint(\n        '%s-roberta-%i.h5'%(VER,fold), monitor='val_loss', verbose=1, save_best_only=True,\n        save_weights_only=True, mode='auto', save_freq='epoch')\n        \n    model.fit([input_ids[idxT,], attention_mask[idxT,], token_type_ids[idxT,]], [start_tokens[idxT,], end_tokens[idxT,]], \n        epochs=3, batch_size=32, verbose=DISPLAY, callbacks=[sv],\n        validation_data=([input_ids[idxV,],attention_mask[idxV,],token_type_ids[idxV,]], \n        [start_tokens[idxV,], end_tokens[idxV,]]))\n    \n    print('Loading model...')\n    model.load_weights('%s-roberta-%i.h5'%(VER,fold))\n    \n    print('Predicting OOF...')\n    oof_start[idxV,],oof_end[idxV,] = model.predict([input_ids[idxV,],attention_mask[idxV,],token_type_ids[idxV,]],verbose=DISPLAY)\n    \n    print('Predicting Test...')\n    preds = model.predict([input_ids_t,attention_mask_t,token_type_ids_t],verbose=DISPLAY)\n    preds_start += preds[0]/skf.n_splits\n    preds_end += preds[1]/skf.n_splits\n    \n    # DISPLAY FOLD JACCARD\n    all = []\n    for k in idxV:\n        a = np.argmax(oof_start[k,])\n        b = np.argmax(oof_end[k,])\n        if a>b: \n            st = train.loc[k,'text'] # IMPROVE CV/LB with better choice here\n        else:\n            text1 = \" \"+\" \".join(train.loc[k,'text'].split())\n            enc = tokenizer.encode(text1)\n            st = tokenizer.decode(enc.ids[a-1:b])\n        all.append(jaccard(st,train.loc[k,'selected_text']))\n    jac.append(np.mean(all))\n    print('>>>> FOLD %i Jaccard ='%(fold+1),np.mean(all))\n    print()","metadata":{"execution":{"iopub.status.busy":"2022-07-10T19:07:44.465660Z","iopub.execute_input":"2022-07-10T19:07:44.465971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Kaggle submission","metadata":{}},{"cell_type":"code","source":"all = []\nfor k in range(input_ids_t.shape[0]):\n    a = np.argmax(preds_start[k,])\n    b = np.argmax(preds_end[k,])\n    if a>b: \n        st = test.loc[k,'text']\n    else:\n        text1 = \" \"+\" \".join(test.loc[k,'text'].split())\n        enc = tokenizer.encode(text1)\n        st = tokenizer.decode(enc.ids[a-1:b])\n    all.append(st)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test['selected_text'] = all\ntest[['textID','selected_text']].to_csv('submission.csv',index=False)\npd.set_option('max_colwidth', 60)\ntest.sample(30)","metadata":{},"execution_count":null,"outputs":[]}]}